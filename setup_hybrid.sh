#!/bin/bash

# ParManus AI - Hybrid Setup (Tools + Vision)

echo "ğŸš€ Setting up ParManus AI with Hybrid Models"
echo "============================================="
echo "ğŸ› ï¸ llama3.2 for tool calling"
echo "ğŸ‘ï¸ llama3.2-vision for vision tasks"
echo ""

# Check if we're in the right directory
if [ ! -f "main.py" ]; then
    echo "âŒ Error: Please run this script from the ParManus AI directory"
    exit 1
fi

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "ğŸ“¦ Installing Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
else
    echo "âœ… Ollama already installed"
fi

# Start Ollama server in background
echo "ğŸ”„ Starting Ollama server..."
ollama serve &
OLLAMA_PID=$!

# Wait for server to start
echo "â³ Waiting for Ollama server to start..."
sleep 5

# Pull both models
echo "ğŸ“¥ Pulling llama3.2 (tools model)..."
ollama pull llama3.2

echo "ğŸ“¥ Pulling llama3.2-vision (vision model)..."
ollama pull llama3.2-vision

# Set up hybrid configuration
echo "âš™ï¸ Setting up hybrid configuration..."
cp config/config_hybrid.toml config/config.toml

# Install Python dependencies
echo "ğŸ“¦ Installing Python dependencies..."
pip install -r requirements.txt

# Test the hybrid system
echo ""
echo "ğŸ§ª Testing hybrid system..."
echo "Testing tools capability..."
python main.py --prompt "What tools do you have available?" --no-wait

echo ""
echo "Testing vision capability..."
python main.py --prompt "Describe what you can see in images" --no-wait

echo ""
echo "âœ… Hybrid setup complete!"
echo ""
echo "ğŸ¯ Your ParManus AI now has:"
echo "   ğŸ› ï¸ Full tool calling (llama3.2)"
echo "   ğŸ‘ï¸ Vision capabilities (llama3.2-vision)"
echo "   ğŸ¤– Smart routing between models"
echo "   ğŸŒ Browser automation"
echo "   ğŸ“ File operations"
echo "   ğŸ’» Code execution"
echo "   ğŸ” Web search"
echo ""
echo "ğŸš€ Usage examples:"
echo "   # Tool-based tasks (uses llama3.2)"
echo "   python main.py --prompt 'review google.com'"
echo "   python main.py --agent code --prompt 'write a Python script'"
echo ""
echo "   # Vision tasks (uses llama3.2-vision)"
echo "   python main.py --prompt 'analyze this screenshot'"
echo "   python main.py --prompt 'describe what you see'"
echo ""
echo "   # Interactive mode"
echo "   python main.py"
echo ""
echo "ğŸ›‘ To stop Ollama server:"
echo "   kill $OLLAMA_PID"
echo ""
echo "ğŸ“‹ Available models:"
ollama list

