#!/bin/bash

# ParManus AI - Ollama Setup Script

echo "ğŸš€ Setting up ParManus AI with Ollama (Simplified)"
echo "================================================="

# Check if we're in the right directory
if [ ! -f "main.py" ]; then
    echo "âŒ Error: Please run this script from the ParManus AI directory"
    exit 1
fi

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "ğŸ“¦ Installing Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
else
    echo "âœ… Ollama already installed"
fi

# Start Ollama server in background
echo "ğŸ”„ Starting Ollama server..."
ollama serve &
OLLAMA_PID=$!

# Wait for server to start
echo "â³ Waiting for Ollama server to start..."
sleep 5

# Pull required model
echo "ğŸ“¥ Pulling Llama 3.2 Vision model..."
ollama pull llama3.2-vision

# Install Python dependencies (simplified)
echo "ğŸ“¦ Installing Python dependencies..."
pip install -r requirements.txt

# Test the system
echo "ğŸ§ª Testing the system..."
python main.py --prompt "Hello, test the Ollama-only system" --no-wait

echo ""
echo "âœ… Setup complete!"
echo ""
echo "ğŸ¯ ParManus AI is now running with:"
echo "   â€¢ Ollama backend only (no llama-cpp-python)"
echo "   â€¢ Llama 3.2 Vision model (unified text + vision)"
echo "   â€¢ Full tool calling support"
echo "   â€¢ All agent types available"
echo ""
echo "ğŸš€ Usage examples:"
echo "   python main.py --prompt 'review google.com'"
echo "   python main.py --agent code --prompt 'write a Python script'"
echo "   python main.py --agent browser --prompt 'search for AI news'"
echo "   python main.py  # Interactive mode"
echo ""
echo "ğŸ›‘ To stop Ollama server:"
echo "   kill $OLLAMA_PID"
echo ""
echo "ğŸ“‹ Available models:"
ollama list

